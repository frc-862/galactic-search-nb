{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/edurso/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['A-BLUE', 'A-RED', 'B-BLUE', 'B-RED']\n",
    "img_cols = 160\n",
    "img_rows = 120\n",
    "\n",
    "def read_img(path, img, class_num, data):\n",
    "    try:\n",
    "        img_arr = cv2.imread(os.path.join(path, img)) # read image with opencv\n",
    "        if img_arr.shape[0] == img_rows and img_arr.shape[1] == img_cols:\n",
    "            data.append([img_arr, class_num]) # add to final data list\n",
    "        else:\n",
    "            print('File at', os.path.join(path,img), 'does not have proper size')\n",
    "            print('Expected ({}x{}}) but got ({}x{})'.format(img_rows,img_cols,img_arr.rows,img_arr.cols))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def read_data(data_dir, train_set_size_per_cat, val_set_size_per_cat):\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    \n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "        images = os.listdir(path) # list of images in directory\n",
    "        training_images = random.sample(images, train_set_size_per_cat) # select 40 random images for training\n",
    "        images = [image for image in images if image not in training_images] # remove selected images\n",
    "        validation_images = random.sample(images, val_set_size_per_cat) # select 10 random validation images\n",
    "        \n",
    "        # read the training images\n",
    "        for img in training_images:\n",
    "            read_img(path, img, class_num, train_data)\n",
    "                \n",
    "        # read the validation images\n",
    "        for img in validation_images:\n",
    "            read_img(path, img, class_num, val_data)\n",
    "    \n",
    "    return np.array(train_data), np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edurso/.local/lib/python3.6/site-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "train, val = read_data('input', 40, 10)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n",
    "# normalize\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_val = keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center             =False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center              =False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization  =False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization   =False,  # divide each input by its std\n",
    "        zca_whitening                  =False,  # apply ZCA whitening\n",
    "        rotation_range                 =3,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range                     =0.1,    # Randomly zoom image \n",
    "        width_shift_range              =0.1,    # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range             =0.1,    # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip                =False,  # randomly flip images\n",
    "        vertical_flip                  =False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(rows, cols):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(rows,cols,3)),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(112, activation=\"relu\"),\n",
    "        keras.layers.Dense(56, activation=\"relu\"),\n",
    "        keras.layers.Dense(56, activation=\"relu\"),\n",
    "        keras.layers.Dense(4, activation=\"softmax\"),\n",
    "    ])\n",
    "    opt = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/25\n",
      "160/160 - 9s - loss: 1.3832 - acc: 0.2375 - val_loss: 1.3431 - val_acc: 0.5500\n",
      "Epoch 2/25\n",
      "160/160 - 8s - loss: 1.2893 - acc: 0.6125 - val_loss: 1.2005 - val_acc: 0.3750\n",
      "Epoch 3/25\n",
      "160/160 - 7s - loss: 1.0969 - acc: 0.5437 - val_loss: 0.8983 - val_acc: 1.0000\n",
      "Epoch 4/25\n",
      "160/160 - 8s - loss: 0.6328 - acc: 0.9375 - val_loss: 0.2624 - val_acc: 1.0000\n",
      "Epoch 5/25\n",
      "160/160 - 7s - loss: 0.2084 - acc: 0.9312 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 6/25\n",
      "160/160 - 7s - loss: 0.0423 - acc: 0.9937 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 7/25\n",
      "160/160 - 7s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 8/25\n",
      "160/160 - 6s - loss: 0.0021 - acc: 1.0000 - val_loss: 4.3716e-04 - val_acc: 1.0000\n",
      "Epoch 9/25\n",
      "160/160 - 7s - loss: 4.4306e-04 - acc: 1.0000 - val_loss: 3.4861e-04 - val_acc: 1.0000\n",
      "Epoch 10/25\n",
      "160/160 - 7s - loss: 3.9981e-04 - acc: 1.0000 - val_loss: 2.0351e-04 - val_acc: 1.0000\n",
      "Epoch 11/25\n",
      "160/160 - 7s - loss: 2.0590e-04 - acc: 1.0000 - val_loss: 7.5015e-05 - val_acc: 1.0000\n",
      "Epoch 12/25\n",
      "160/160 - 8s - loss: 6.9154e-05 - acc: 1.0000 - val_loss: 3.4362e-05 - val_acc: 1.0000\n",
      "Epoch 13/25\n",
      "160/160 - 7s - loss: 6.3934e-05 - acc: 1.0000 - val_loss: 2.0780e-05 - val_acc: 1.0000\n",
      "Epoch 14/25\n",
      "160/160 - 7s - loss: 3.7789e-05 - acc: 1.0000 - val_loss: 1.5491e-05 - val_acc: 1.0000\n",
      "Epoch 15/25\n",
      "160/160 - 8s - loss: 2.5087e-05 - acc: 1.0000 - val_loss: 1.2925e-05 - val_acc: 1.0000\n",
      "Epoch 16/25\n",
      "160/160 - 8s - loss: 2.9920e-05 - acc: 1.0000 - val_loss: 1.1423e-05 - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      "160/160 - 7s - loss: 2.2564e-05 - acc: 1.0000 - val_loss: 1.0347e-05 - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      "160/160 - 7s - loss: 1.8769e-05 - acc: 1.0000 - val_loss: 9.5246e-06 - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "160/160 - 8s - loss: 2.3832e-05 - acc: 1.0000 - val_loss: 8.8750e-06 - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "160/160 - 7s - loss: 2.1440e-05 - acc: 1.0000 - val_loss: 8.3386e-06 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "160/160 - 5s - loss: 1.9903e-05 - acc: 1.0000 - val_loss: 7.9273e-06 - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "160/160 - 6s - loss: 1.3711e-05 - acc: 1.0000 - val_loss: 7.5846e-06 - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "160/160 - 7s - loss: 1.6996e-05 - acc: 1.0000 - val_loss: 7.2448e-06 - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "160/160 - 7s - loss: 1.2672e-05 - acc: 1.0000 - val_loss: 6.9468e-06 - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "160/160 - 7s - loss: 2.1569e-05 - acc: 1.0000 - val_loss: 6.6369e-06 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = create_model(img_rows, img_cols)\n",
    "history = model.fit(x_train, y_train, epochs=25, validation_data=(x_val, y_val), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 6.6369e-06 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_val, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img, expected):\n",
    "    res = model.predict(img)\n",
    "    real = expected\n",
    "    \n",
    "    int_res_one_hot = [int(round(r)) for r in res[0]]\n",
    "    int_real_one_hot = [int(round(r)) for r in real]\n",
    "    #print('Encoded Result: {} | Encoded Expected: {}'.format(int_res_one_hot, int_real_one_hot))\n",
    "    \n",
    "    res_idx = -1\n",
    "    real_idx = -1\n",
    "    res_ = 'NONE'\n",
    "    real_ = 'NONE'\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        res_idx = int_res_one_hot.index(1)\n",
    "        real_idx = int_real_one_hot.index(1)\n",
    "        #print('Result Index: {} | Expected Index: {}'.format(res_idx, real_idx))\n",
    "        \n",
    "        res_ = labels[res_idx]\n",
    "        real_ = labels[real_idx]\n",
    "        #print('Result Index: {} | Expected Index: {}'.format(res_, real_))\n",
    "        \n",
    "    except:\n",
    "        print('NONE')    \n",
    "    \n",
    "    prediction = res_\n",
    "    expected = real_\n",
    "    correct = (prediction == expected)\n",
    "    \n",
    "    return prediction, expected, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference On A Few Random Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Index: A-BLUE | Expected Index: A-BLUE\n",
      "Result Index: A-RED | Expected Index: A-RED\n",
      "Result Index: B-BLUE | Expected Index: B-BLUE\n",
      "Result Index: B-RED | Expected Index: B-RED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edurso/.local/lib/python3.6/site-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "data, _ = read_data('input', 1, 0) # read one image from each category\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for feature, label in data:\n",
    "    x.append(feature)\n",
    "    y.append(label)\n",
    "    \n",
    "x = np.array(x) / 255\n",
    "y = keras.utils.to_categorical(np.array(y))\n",
    "    \n",
    "for img, real in zip(x, y):\n",
    "    img.resize(1, img_rows, img_cols, 3) # TODO why is this necessary?\n",
    "    prediction, expected, correct = inference(model, img, real)\n",
    "    print('Result Index: {} | Expected Index: {}'.format(prediction, expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Misclassified Samples\n",
    "If no images are printed, there are no misclassified samples and that is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edurso/.local/lib/python3.6/site-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "data, _ = read_data('input', 500, 0) # read 50 images from each category\n",
    "\n",
    "x_ = []\n",
    "y_ = []\n",
    "\n",
    "for feature, label in data:\n",
    "    x_.append(feature)\n",
    "    y_.append(label)\n",
    "    \n",
    "x_ = np.array(x_) / 255\n",
    "y_ = keras.utils.to_categorical(np.array(y_))\n",
    "    \n",
    "for img, real in zip(x_, y_):\n",
    "    img.resize(1, img_rows, img_cols, 3) # TODO why is this necessary?\n",
    "    prediction, expected, correct = inference(model, img, real)\n",
    "    if not correct:\n",
    "        message = 'Model predicted \"{}\" but label is \"{}\"'.format(prediction, expected)\n",
    "        print(message)\n",
    "        plt.figure(figsize=(5,5))\n",
    "        tmp = img.copy()[0]\n",
    "        plt.imshow(tmp)\n",
    "        plt.title(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./final-classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
